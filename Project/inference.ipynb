{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9C-zS5uH_iD",
        "outputId": "aa0ac891-a021-42e7-e04e-709f602977c1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Comp4211_project/Project\n",
        "%ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0V3709yFuJz",
        "outputId": "4e57f48d-3c94-4c30-e31a-b259e31a2241"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Comp4211_project/Project\n",
            "\u001b[0m\u001b[01;34mclassifier\u001b[0m/       config.py  \u001b[01;34mCycleGAN_save\u001b[0m/  \u001b[01;34mdataset\u001b[0m/         \u001b[01;34m__pycache__\u001b[0m/  test.ipynb\n",
            "\u001b[01;34mClassifier_save\u001b[0m/  \u001b[01;34mcyclegan\u001b[0m/  \u001b[01;34mdata\u001b[0m/           inference.ipynb  \u001b[01;34msamples\u001b[0m/      train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from classifier.classifier import Classifier\n",
        "from data.dataloader import DataLoader_Classifier\n",
        "from config import opt\n",
        "import os\n",
        "opt = opt()\n"
      ],
      "metadata": {
        "id": "IBMszKYBIglR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "netC = Classifier(input_size=64)\n",
        "save_path = opt.classifier_save_path\n",
        "check_point = 50\n",
        "name_type = opt.name_T\n",
        "netC.load_state_dict(torch.load(os.path.join(save_path, f\"{name_type}/netC_{check_point}.pth\")))\n",
        "netC.eval()\n",
        "netC.cuda()\n",
        "\n",
        "dataloader = DataLoader_Classifier(img_size=64)\n",
        "labels_name = dataloader.get_labels_names()\n",
        "idx_to_class = {v: k for k, v in labels_name.items()}\n",
        "print(idx_to_class)"
      ],
      "metadata": {
        "id": "v-SyAeviJCpi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a363b79-fc3f-433f-f5d1-dcd4a51c0241"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'lung_aca', 1: 'lung_n', 2: 'lung_scc'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:558: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from cyclegan.cyclegan import cycleD, cycleG\n",
        "\n",
        "netG_aca_n = cycleG()\n",
        "netG_scc_n = cycleG()\n",
        "netG_aca_scc = cycleG()\n",
        "# Load the model\n",
        "check_point_aca_n = 25\n",
        "check_point_scc_n = 25\n",
        "check_point_aca_scc = 25\n",
        "save_path = opt.gan_save_path\n",
        "name_type = opt.name_T\n",
        "\n",
        "name_A = 'lung_aca'\n",
        "name_B = 'lung_n'\n",
        "name_C = 'lung_scc'\n",
        "\n",
        "netG_aca_n.load_state_dict(torch.load(os.path.join(save_path, f\"generator/{name_type}/{name_A}_and_{name_B}/netG_{check_point_aca_n}.pth\")))\n",
        "netG_scc_n.load_state_dict(torch.load(os.path.join(save_path, f\"generator/{name_type}/{name_C}_and_{name_B}/netG_{check_point_scc_n}.pth\")))\n",
        "netG_aca_scc.load_state_dict(torch.load(os.path.join(save_path, f\"generator/{name_type}/{name_A}_and_{name_C}/netG_{check_point_aca_scc}.pth\")))\n",
        "\n",
        "netG_aca_n.eval().cuda()\n",
        "netG_scc_n.eval().cuda()\n",
        "netG_aca_scc.eval().cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loPmEuYcK6Dw",
        "outputId": "24764750-4ca1-44bd-a779-7844796f6c9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded from epoch 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "def transform (size):\n",
        "  return transforms.Compose([\n",
        "    transforms.Resize((size, size)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "def inference(image_sc): # image path\n",
        "  raw_image = Image.open(image_path).convert('RGB')\n",
        "  image = transform(64).transform(raw_image).unsqueeze(0).cuda()\n",
        "  output = netC(image)\n",
        "  _ , predicted = torch.max(output.data,1)\n",
        "  predicted_class = idx_to_class[predicted.item()]\n",
        "\n",
        "  image = transform(96).transform(raw_image).unsqueeze(0).cuda()\n",
        "  blank =  torch.zeros(1,3,96,96).cuda()\n",
        "  match predicted_class:\n",
        "    case 'lung_aca':\n",
        "      image_aca = image\n",
        "      _, image_n = netG_aca_n(image, blank)\n",
        "      _, image_scc = netG_aca_scc(image,blank)\n",
        "    case 'lung_scc':\n",
        "      image_scc = image\n",
        "      _, image_n = netG_scc_n(image, blank)\n",
        "      image_aca, _ = netG_aca_scc(blank,image)\n",
        "    case 'lung_n':\n",
        "      image_n = image\n",
        "      image_aca, _ = netG_aca_n(blank, image)\n",
        "      image_scc, _ = netG_scc_n(blank, image)\n",
        "\n",
        "  image_aca = image.cpu().detach().numpy()\n",
        "  image_n = image_n.cpu().detach().numpy()\n",
        "  image_scc = image_scc.cpu().detach().numpy()\n",
        "\n",
        "  np.transpose(image_aca, (0, 2, 3, 1))\n",
        "  np.transpose(image_n, (0, 2, 3, 1))\n",
        "  np.transpose(image_scc, (0, 2, 3, 1))\n",
        "\n",
        "  plt.figure(figsize=(10, 10))\n",
        "\n",
        "  plt.subplot(3, 1, 1)\n",
        "  plt.imshow(image_n[0])\n",
        "  if predicted_class == 'lung_n':\n",
        "    plt.title('n(real)')\n",
        "  else:\n",
        "    plt.title('n(fake)')\n",
        "\n",
        "  plt.subplot(3, 1, 2)\n",
        "  plt.imshow(image_aca[0])\n",
        "  if predicted_class == 'lung_aca':\n",
        "    plt.title('aca(real)')\n",
        "  else:\n",
        "    plt.title('aca(fake)')\n",
        "\n",
        "  plt.subplot(3, 1, 3)\n",
        "  plt.imshow(image_scc[0])\n",
        "  if predicted_class == 'lung_scc':\n",
        "    plt.title('scc(real)')\n",
        "  else:\n",
        "    plt.title('scc(fake)')\n",
        "\n",
        "  return\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8iiJp6-CiO7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((96, 96)),\n",
        "#     transforms.ToTensor(),\n",
        "# ])\n",
        "\n",
        "# # Load the image\n",
        "# image_path = \"/content/drive/MyDrive/Comp4211_tempt/Project/lungaca10.jpeg（副本）\"\n",
        "# image = Image.open(image_path).convert('RGB')\n",
        "\n",
        "\n",
        "# # Apply the transformation\n",
        "# image = transform(image).unsqueeze(0).cuda()\n",
        "# blank =  torch.zeros(1,3,96,96).cuda()\n",
        "# _, guess = netG(image, blank)\n",
        "# guess = guess.cpu().detach().numpy()\n",
        "# image = image.cpu().detach().numpy()\n",
        "\n",
        "\n",
        "# guess = np.transpose(guess, (0, 2, 3, 1))\n",
        "# image = np.transpose(image, (0, 2, 3, 1))\n",
        "\n",
        "\n",
        "\n",
        "# plt.figure(figsize=(10, 10))\n",
        "\n",
        "# plt.subplot(2, 1, 1)\n",
        "# plt.imshow(image[0])\n",
        "# plt.title('Real A')\n",
        "\n",
        "# plt.subplot(2, 1, 2)\n",
        "# plt.imshow(guess[0])\n",
        "# plt.title('Fake B')\n",
        "\n"
      ],
      "metadata": {
        "id": "bMYfQIeSpOcL"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "1a7e222cc2a766296ab268e605fd50be26f6c7645da09cf2d401f013c1a6b14e"
      }
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}